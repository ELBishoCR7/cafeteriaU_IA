import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
import joblib

def entrenar_cerebro():
    print("â³ Cargando y procesando datos...")
    
    # 1. Cargar datos
    try:
        df = pd.read_csv('dataset_convertido.csv')
    except FileNotFoundError:
        print("âŒ Error: No se encuentra 'dataset_convertido.csv'. AsegÃºrate de que estÃ© en la misma carpeta.")
        return

    # 2. Limpieza y ConversiÃ³n de Fechas (Manejo robusto de formatos mixtos)
    # Intentamos inferir el formato. Si hay fechas como '30-02', las convertirÃ¡ en NaT (Not a Time)
    df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=False)
    
    # Eliminar filas donde la fecha o la cantidad sean invÃ¡lidas
    df = df.dropna(subset=['date', 'quantity'])
    
    # Asegurar que 'quantity' es numÃ©rico
    df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce').fillna(0)

    # 3. Feature Engineering (Variables para la IA)
    df['day_of_week'] = df['date'].dt.dayofweek
    df['month'] = df['date'].dt.month
    df['day'] = df['date'].dt.day

    # Codificar el nombre del producto (Texto -> NÃºmero)
    le = LabelEncoder()
    df['item_code'] = le.fit_transform(df['item_name'])

    # --- MÃ“DULO 1: PREDICCIÃ“N DE DEMANDA (CORREGIDO) ---
    print("ğŸ§  Entrenando modelo de predicciÃ³n de cantidad...")
    
    # X = Features (DÃ­a, Mes, AÃ±o, Producto ID)
    X = df[['day_of_week', 'month', 'day', 'item_code']]
    
    # Y = Target (CORREGIDO: Ahora apuntamos a 'quantity', NO a 'item_type')
    y = df['quantity'] 

    # Usamos RandomForestRegressor (Regresor = predice nÃºmeros, no categorÃ­as)
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X, y)

    # --- MÃ“DULO 2: DETECCIÃ“N DE TENDENCIAS ---
    print("ğŸ“ˆ Analizando tendencias de mercado...")
    trend_info = {}
    
    if not df.empty:
        latest_date = df['date'].max()
        start_date = latest_date - pd.Timedelta(days=30) # Ãšltimos 30 dÃ­as
        recent_data = df[df['date'] >= start_date]

        for item in df['item_name'].unique():
            item_data = recent_data[recent_data['item_name'] == item].groupby('date')['quantity'].sum().reset_index()
            
            status = "Estable â–"
            slope = 0
            
            if len(item_data) > 1:
                # RegresiÃ³n lineal simple para ver la pendiente (slope)
                x_vals = np.arange(len(item_data))
                y_vals = item_data['quantity'].values
                slope = np.polyfit(x_vals, y_vals, 1)[0]
                
                if slope > 0.1: status = "Subiendo ğŸ”¥"
                elif slope < -0.1: status = "Bajando ğŸ“‰"
            
            trend_info[item] = {'slope': round(slope, 3), 'status': status}

    # --- MÃ“DULO 3: HORAS PICO ---
    print("â° Calculando horas pico...")
    # Sumar ventas por 'time_of_sale'
    if 'time_of_sale' in df.columns:
        peak_hours = df.groupby('time_of_sale')['quantity'].sum().sort_values(ascending=False).to_dict()
    else:
        peak_hours = {}
        print("âš ï¸ Advertencia: No se encontrÃ³ columna 'time_of_sale'.")

    # 4. Guardar todo en un solo archivo .pkl
    artifacts = {
        'model': model,      # El cerebro que predice nÃºmeros
        'encoder': le,       # El traductor de nombres a cÃ³digos
        'trends': trend_info,# Datos de quÃ© sube/baja
        'peak_hours': peak_hours # Datos de horas pico
    }
    
    joblib.dump(artifacts, 'cerebro_completo.pkl')
    print("âœ… Â¡Ã‰xito! Archivo 'cerebro_completo.pkl' generado correctamente.")
    print(f"   - Modelo entrenado con {len(df)} registros.")

if __name__ == "__main__":
    entrenar_cerebro()